import torch
import numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, BertModel, GPT2Model
from transformers import BertForSequenceClassification, GPT2LMHeadModel
import warnings
warnings.filterwarnings('ignore')

class BERTGPTComparison:
    def __init__(self):
        """åˆå§‹åŒ–å¯¹æ¯”åˆ†æç±»"""
        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

    def load_models(self):
        """åŠ è½½BERTå’ŒGPTæ¨¡å‹"""
        print("=== åŠ è½½æ¨¡å‹è¿›è¡Œå¯¹æ¯” ===")

        try:
            # BERTæ¨¡å‹
            self.bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')
            self.bert_model = BertModel.from_pretrained('bert-base-chinese').to(self.device)
            self.bert_classifier = BertForSequenceClassification.from_pretrained(
                'bert-base-chinese', num_labels=2
            ).to(self.device)

            # GPTæ¨¡å‹
            self.gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')
            self.gpt_tokenizer.pad_token = self.gpt_tokenizer.eos_token
            self.gpt_model = GPT2Model.from_pretrained('gpt2').to(self.device)
            self.gpt_generator = GPT2LMHeadModel.from_pretrained('gpt2').to(self.device)

            print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
            return True

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æœ¬åœ°")
            print("   ç¦»çº¿æ¨¡å¼: è®¾ç½®ç¯å¢ƒå˜é‡ HF_HUB_OFFLINE=1")
            print("   æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°: ~/.cache/huggingface/hub/")
            return False

    def compare_architectures(self):
        """1. æ¶æ„å¯¹æ¯”åˆ†æ"""
        print("\n=== 1. æ¶æ„å¯¹æ¯”åˆ†æ ===")

        architecture_comparison = {
            "æ ¸å¿ƒæ¶æ„": {
                "BERT": "åŒå‘Transformerç¼–ç å™¨",
                "GPT": "å•å‘Transformerè§£ç å™¨"
            },
            "æ³¨æ„åŠ›æœºåˆ¶": {
                "BERT": "å…¨è¯æ³¨æ„åŠ›ï¼ˆæ— æ©ç ï¼‰",
                "GPT": "å› æœæ©ç è‡ªæ³¨æ„åŠ›"
            },
            "è¾“å…¥å¤„ç†": {
                "BERT": "[CLS] + å¥å­å¯¹",
                "GPT": "åºåˆ—è‡ªå›å½’"
            },
            "è¾“å‡ºæ–¹å¼": {
                "BERT": "ä¸Šä¸‹æ–‡è¡¨å¾å‘é‡",
                "GPT": "ä¸‹ä¸€ä¸ªtokené¢„æµ‹"
            }
        }

        print("æ¶æ„å¯¹æ¯”:")
        for aspect, models in architecture_comparison.items():
            print(f"\n{aspect}:")
            print(f"  BERT: {models['BERT']}")
            print(f"  GPT: {models['GPT']}")

    def compare_pretraining_tasks(self):
        """2. é¢„è®­ç»ƒä»»åŠ¡å¯¹æ¯”"""
        print("\n=== 2. é¢„è®­ç»ƒä»»åŠ¡å¯¹æ¯” ===")

        task_comparison = {
            "ä¸»è¦ä»»åŠ¡": {
                "BERT": "MLMï¼ˆæ©ç è¯­è¨€å»ºæ¨¡ï¼‰+ NSPï¼ˆä¸‹ä¸€å¥é¢„æµ‹ï¼‰",
                "GPT": "è‡ªå›å½’è¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€è¯ï¼‰"
            },
            "è®­ç»ƒç›®æ ‡": {
                "BERT": "å­¦ä¹ åŒå‘ä¸Šä¸‹æ–‡è¡¨å¾",
                "GPT": "å­¦ä¹ ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒ"
            },
            "æ•°æ®åˆ©ç”¨": {
                "BERT": "åˆ©ç”¨å·¦å³ä¸Šä¸‹æ–‡",
                "GPT": "åˆ©ç”¨å‰åºä¸Šä¸‹æ–‡"
            },
            "æ³›åŒ–èƒ½åŠ›": {
                "BERT": "å¼ºç†è§£èƒ½åŠ›",
                "GPT": "å¼ºç”Ÿæˆèƒ½åŠ›"
            }
        }

        print("é¢„è®­ç»ƒä»»åŠ¡å¯¹æ¯”:")
        for aspect, models in task_comparison.items():
            print(f"\n{aspect}:")
            print(f"  BERT: {models['BERT']}")
            print(f"  GPT: {models['GPT']}")

    def demonstrate_bert_bidirectional(self):
        """3. BERTåŒå‘æ€§æ¼”ç¤º"""
        print("\n=== 3. BERTåŒå‘æ€§æ¼”ç¤º ===")

        text = "è‡ªç„¶è¯­è¨€å¤„ç†[NLP]æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"
        masked_text = "è‡ªç„¶è¯­è¨€å¤„ç†[MASK]æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"




        print(f"åŸå§‹æ–‡æœ¬: {text}")
        print(f"æ©ç æ–‡æœ¬: {masked_text}")
        # åˆ†è¯
        print(self.bert_tokenizer(masked_text))
        inputs = self.bert_tokenizer(masked_text, return_tensors='pt').to(self.device)

        with torch.no_grad():
            outputs = self.bert_classifier(**inputs)  # ä½¿ç”¨åˆ†ç±»å™¨æ¼”ç¤º
            logits = outputs.logits

        print("BERTèƒ½å¤Ÿåˆ©ç”¨å·¦å³ä¸Šä¸‹æ–‡è¿›è¡Œé¢„æµ‹")
        print("âœ“ åŒå‘æ³¨æ„åŠ›æœºåˆ¶ç¤ºä¾‹")

    def demonstrate_gpt_unidirectional(self):
        """4. GPTå•å‘æ€§æ¼”ç¤º"""
        print("\n=== 4. GPTå•å‘æ€§æ¼”ç¤º ===")

        text = "The weather today is"
        print(f"è¾“å…¥åºåˆ—: {text}")

        inputs = self.gpt_tokenizer(text, return_tensors='pt').to(self.device)

        with torch.no_grad():
            outputs = self.gpt_generator(**inputs)
            next_token_logits = outputs.logits[:, -1, :]

        # Top 3é¢„æµ‹
        top_k = 3
        top_tokens = torch.topk(next_token_logits, top_k, dim=-1)

        print("GPTåªèƒ½åˆ©ç”¨å‰åºä¸Šä¸‹æ–‡é¢„æµ‹:")
        for i in range(top_k):
            token_id = top_tokens.indices[0, i].item()
            token = self.gpt_tokenizer.decode(token_id)
            prob = torch.softmax(next_token_logits, dim=-1)[0, token_id].item()
            print(f"  {token}: {prob:.4f}")

    def compare_fine_tuning(self):
        """5. å¾®è°ƒç­–ç•¥å¯¹æ¯”"""
        print("\n=== 5. å¾®è°ƒç­–ç•¥å¯¹æ¯” ===")

        finetune_comparison = {
            "é€‚ç”¨åœºæ™¯": {
                "BERT": "åˆ†ç±»ã€é—®ç­”ã€NERç­‰ç†è§£ä»»åŠ¡",
                "GPT": "ç”Ÿæˆã€å¯¹è¯ã€ç¿»è¯‘ç­‰ç”Ÿæˆä»»åŠ¡"
            },
            "å‚æ•°æ•ˆç‡": {
                "BERT": "æ–°å¢å°‘é‡å‚æ•°ï¼ˆåˆ†ç±»å¤´ï¼‰",
                "GPT": "é€šå¸¸å…¨å‚æ•°å¾®è°ƒ"
            },
            "æ•°æ®éœ€æ±‚": {
                "BERT": "éœ€è¦æ ‡æ³¨æ•°æ®",
                "GPT": "å¯ä½¿ç”¨æ— ç›‘ç£æ•°æ®"
            },
            "è®­ç»ƒç›®æ ‡": {
                "BERT": "æœ€å°åŒ–äº¤å‰ç†µæŸå¤±",
                "GPT": "æœ€å°åŒ–è¯­è¨€å»ºæ¨¡æŸå¤±"
            }
        }

        print("å¾®è°ƒç­–ç•¥å¯¹æ¯”:")
        for aspect, models in finetune_comparison.items():
            print(f"\n{aspect}:")
            print(f"  BERT: {models['BERT']}")
            print(f"  GPT: {models['GPT']}")

    def compare_performance_metrics(self):
        """6. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”"""
        print("\n=== 6. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯” ===")

        performance_data = {
            "GLUEåŸºå‡†": {
                "BERT_Base": "87.1",
                "GPT": "è¾ƒå¼±"
            },
            "ç”Ÿæˆè¿è´¯æ€§": {
                "BERT": "è¾ƒå¼±",
                "GPT": "92%"
            },
            "SQuAD_F1": {
                "BERT": "93.2",
                "GPT": "è¾ƒå¼±"
            },
            "å‚æ•°é‡çº§": {
                "BERT_Base": "1.1äº¿",
                "GPT_3": "1750äº¿"
            }
        }

        print("æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”:")
        print("æŒ‡æ ‡\t\tBERT\t\tGPT")
        print("-" * 40)
        for metric, scores in performance_data.items():
            bert_score = scores.get('BERT_Base', scores.get('BERT', 'N/A'))
            gpt_score = scores.get('GPT_3', scores.get('GPT', 'N/A'))
            print(f"{metric:<12}\t{bert_score:<12}\t{gpt_score}")

    def compare_applications(self):
        """7. åº”ç”¨åœºæ™¯å¯¹æ¯”"""
        print("\n=== 7. åº”ç”¨åœºæ™¯å¯¹æ¯” ===")

        applications = {
            "æ–‡æœ¬åˆ†ç±»": {
                "BERT": "â˜…â˜…â˜…â˜…â˜… (IMDb 94.9%)",
                "GPT": "â˜…â˜…â˜…â˜†â˜†"
            },
            "é—®ç­”ç³»ç»Ÿ": {
                "BERT": "â˜…â˜…â˜…â˜…â˜… (SQuAD F1 93.2)",
                "GPT": "â˜…â˜…â˜…â˜†â˜†"
            },
            "æ–‡æœ¬ç”Ÿæˆ": {
                "BERT": "â˜…â˜…â˜†â˜†â˜†",
                "GPT": "â˜…â˜…â˜…â˜…â˜… (é‡‡çº³ç‡72%)"
            },
            "ä»£ç ç”Ÿæˆ": {
                "BERT": "â˜…â˜…â˜…â˜†â˜†",
                "GPT": "â˜…â˜…â˜…â˜…â˜†"
            },
            "å¯¹è¯ç³»ç»Ÿ": {
                "BERT": "â˜…â˜…â˜…â˜†â˜†",
                "GPT": "â˜…â˜…â˜…â˜…â˜…"
            },
            "å‘½åå®ä½“è¯†åˆ«": {
                "BERT": "â˜…â˜…â˜…â˜…â˜… (F1 96.6%)",
                "GPT": "â˜…â˜…â˜†â˜†â˜†"
            }
        }

        print("åº”ç”¨åœºæ™¯é€‚ç”¨æ€§:")
        for task, models in applications.items():
            print(f"\n{task}:")
            print(f"  BERT: {models['BERT']}")
            print(f"  GPT: {models['GPT']}")

    def demonstrate_joint_usage(self):
        """8. è”åˆä½¿ç”¨æ¼”ç¤º"""
        print("\n=== 8. BERTä¸GPTè”åˆä½¿ç”¨ ===")

        print("BERT + GPT è”åˆåº”ç”¨æ¨¡å¼:")

        joint_usage = {
            "1. BERTç†è§£ + GPTç”Ÿæˆ": "å…ˆç”¨BERTåˆ†æç”¨æˆ·æ„å›¾ï¼Œå†ç”¨GPTç”Ÿæˆå“åº”",
            "2. GPTç”Ÿæˆ + BERTæ ¡éªŒ": "GPTç”Ÿæˆå†…å®¹åç”¨BERTè¿›è¡Œè´¨é‡è¯„ä¼°",
            "3. å¤šä»»åŠ¡å­¦ä¹ ": "åŒä¸€ä¸ªæ¶æ„åŒæ—¶å­¦ä¹ ç†è§£å’Œç”Ÿæˆä»»åŠ¡",
            "4. çŸ¥è¯†å¢å¼º": "BERTæä¾›çŸ¥è¯† groundingï¼ŒGPTè¿›è¡Œåˆ›æ„ç”Ÿæˆ"
        }

        for mode, description in joint_usage.items():
            print(f"{mode}")
            print(f"   {description}")

    def create_decision_tree(self):
        """9. ä»»åŠ¡é€‰æ‹©å†³ç­–æ ‘"""
        print("\n=== 9. ä»»åŠ¡é€‰æ‹©å†³ç­–æ ‘ ===")

        decision_tree = """
æ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ä½ çš„NLPä»»åŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ç†è§£ä»»åŠ¡ â”‚        â”‚ç”Ÿæˆä»»åŠ¡ â”‚
   â”‚(åˆ†ç±»/é—®ç­”â”‚        â”‚(å†™ä½œ/å¯¹è¯â”‚
   â”‚ /NER)    â”‚        â”‚ /ç¿»è¯‘)   â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ é€‰æ‹©BERT â”‚        â”‚ é€‰æ‹©GPT  â”‚
   â”‚ (åŒå‘ä¼˜  â”‚        â”‚ (ç”Ÿæˆä¼˜  â”‚
   â”‚ åŠ¿æ˜æ˜¾)  â”‚        â”‚ åŠ¿æ˜æ˜¾)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """

        print(decision_tree)

    def run_comparison_analysis(self):
        """è¿è¡Œå®Œæ•´çš„å¯¹æ¯”åˆ†æ"""
        print("ğŸš€ å¼€å§‹BERTä¸GPTå¯¹æ¯”åˆ†æ\n")

        if not self.load_models():
            print("\nâš ï¸  ç”±äºæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè·³è¿‡éœ€è¦æ¨¡å‹çš„æ¼”ç¤º")
            print("ğŸ“– å±•ç¤ºç†è®ºå¯¹æ¯”åˆ†æ:")

        self.compare_architectures()
        self.compare_pretraining_tasks()
        self.demonstrate_bert_bidirectional()
        # self.compare_fine_tuning()
        # self.compare_performance_metrics()
        # self.compare_applications()
        # self.demonstrate_joint_usage()
        # self.create_decision_tree()

        # print("\nğŸ‰ BERTä¸GPTå¯¹æ¯”åˆ†æå®Œæˆï¼")
        #
        # # æ€»ç»“
        # print("\n" + "="*50)
        # print("ğŸ“Š å¯¹æ¯”æ€»ç»“:")
        # print("â€¢ BERT: æ“…é•¿ç†è§£ä»»åŠ¡ï¼Œé€‚åˆåˆ†ç±»ã€é—®ç­”ã€NERç­‰")
        # print("â€¢ GPT: æ“…é•¿ç”Ÿæˆä»»åŠ¡ï¼Œé€‚åˆå†™ä½œã€å¯¹è¯ã€ä»£ç ç”Ÿæˆç­‰")
        # print("â€¢ å®é™…åº”ç”¨ä¸­å¯æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©æˆ–è”åˆä½¿ç”¨")
        # print("="*50)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    comparison = BERTGPTComparison()
    comparison.run_comparison_analysis()
